{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Simple LUTNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from lutnn.lutlayer import LUTLayer, Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.uci_datasets import BreastCancerDataset\n",
    "import torch\n",
    "\n",
    "train_set = BreastCancerDataset('./data-uci', split='train', download=True, with_val=False)\n",
    "test_set = BreastCancerDataset('./data-uci', split='test', with_val=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=int(1e6), shuffle=False)\n",
    "input_dim_dataset = 51\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple LUTNN\n",
    "class SimpleLUTNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLUTNN, self).__init__()\n",
    "        self.layer1 = LUTLayer(input_dim=51, lut_size=4, n_luts=1024)\n",
    "        self.layer2 = LUTLayer(input_dim=1024, lut_size=4, n_luts=512)\n",
    "        self.layer3 = Aggregation(num_classes=2, tau=10.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = SimpleLUTNN().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [0/2], Loss: 0.7066\n",
      "Epoch [2/50], Step [0/2], Loss: 0.6036\n",
      "Epoch [3/50], Step [0/2], Loss: 0.5712\n",
      "Epoch [4/50], Step [0/2], Loss: 0.6300\n",
      "Epoch [5/50], Step [0/2], Loss: 0.5256\n",
      "Epoch [6/50], Step [0/2], Loss: 0.6100\n",
      "Epoch [7/50], Step [0/2], Loss: 0.5759\n",
      "Epoch [8/50], Step [0/2], Loss: 0.5286\n",
      "Epoch [9/50], Step [0/2], Loss: 0.4743\n",
      "Epoch [10/50], Step [0/2], Loss: 0.5008\n",
      "Epoch [11/50], Step [0/2], Loss: 0.4850\n",
      "Epoch [12/50], Step [0/2], Loss: 0.4768\n",
      "Epoch [13/50], Step [0/2], Loss: 0.4754\n",
      "Epoch [14/50], Step [0/2], Loss: 0.4546\n",
      "Epoch [15/50], Step [0/2], Loss: 0.4598\n",
      "Epoch [16/50], Step [0/2], Loss: 0.4438\n",
      "Epoch [17/50], Step [0/2], Loss: 0.4327\n",
      "Epoch [18/50], Step [0/2], Loss: 0.4014\n",
      "Epoch [19/50], Step [0/2], Loss: 0.4304\n",
      "Epoch [20/50], Step [0/2], Loss: 0.4288\n",
      "Epoch [21/50], Step [0/2], Loss: 0.4249\n",
      "Epoch [22/50], Step [0/2], Loss: 0.3702\n",
      "Epoch [23/50], Step [0/2], Loss: 0.4007\n",
      "Epoch [24/50], Step [0/2], Loss: 0.4012\n",
      "Epoch [25/50], Step [0/2], Loss: 0.4001\n",
      "Epoch [26/50], Step [0/2], Loss: 0.3791\n",
      "Epoch [27/50], Step [0/2], Loss: 0.3837\n",
      "Epoch [28/50], Step [0/2], Loss: 0.3788\n",
      "Epoch [29/50], Step [0/2], Loss: 0.3442\n",
      "Epoch [30/50], Step [0/2], Loss: 0.4164\n",
      "Epoch [31/50], Step [0/2], Loss: 0.3478\n",
      "Epoch [32/50], Step [0/2], Loss: 0.3705\n",
      "Epoch [33/50], Step [0/2], Loss: 0.3655\n",
      "Epoch [34/50], Step [0/2], Loss: 0.3490\n",
      "Epoch [35/50], Step [0/2], Loss: 0.3420\n",
      "Epoch [36/50], Step [0/2], Loss: 0.3272\n",
      "Epoch [37/50], Step [0/2], Loss: 0.3260\n",
      "Epoch [38/50], Step [0/2], Loss: 0.3313\n",
      "Epoch [39/50], Step [0/2], Loss: 0.3425\n",
      "Epoch [40/50], Step [0/2], Loss: 0.3314\n",
      "Epoch [41/50], Step [0/2], Loss: 0.2994\n",
      "Epoch [42/50], Step [0/2], Loss: 0.3127\n",
      "Epoch [43/50], Step [0/2], Loss: 0.2966\n",
      "Epoch [44/50], Step [0/2], Loss: 0.2764\n",
      "Epoch [45/50], Step [0/2], Loss: 0.3067\n",
      "Epoch [46/50], Step [0/2], Loss: 0.3181\n",
      "Epoch [47/50], Step [0/2], Loss: 0.3098\n",
      "Epoch [48/50], Step [0/2], Loss: 0.2610\n",
      "Epoch [49/50], Step [0/2], Loss: 0.2754\n",
      "Epoch [50/50], Step [0/2], Loss: 0.2962\n",
      "Test Accuracy: 71.43%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): LUTLayer(num_luts=1024, lut_size=4)\n",
      "  (2): LUTLayer(num_luts=512, lut_size=4)\n",
      "  (3): Aggregation(num_classes=2, tau=10.0)\n",
      ")\n",
      "tensor([[0, 0, 1,  ..., 0, 1, 1],\n",
      "        [0, 1, 0,  ..., 1, 0, 0],\n",
      "        [1, 0, 1,  ..., 1, 1, 0],\n",
      "        ...,\n",
      "        [1, 0, 1,  ..., 0, 1, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 1],\n",
      "        [1, 1, 0,  ..., 1, 0, 0]])\n",
      "tensor([[0, 0, 0,  ..., 0, 1, 1],\n",
      "        [1, 0, 0,  ..., 0, 1, 0],\n",
      "        [1, 1, 1,  ..., 1, 0, 1],\n",
      "        ...,\n",
      "        [1, 0, 1,  ..., 0, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 0, 1]])\n",
      "VHDL code generated in data/VHDL/breast_lutnn/\n"
     ]
    }
   ],
   "source": [
    "# VHDL generation\n",
    "import os\n",
    "os.chdir('/Users/rhuang/Documents/llnn-ece-x10')  # ensure we're in the project root\n",
    "\n",
    "from hdl.convert2vhdl import get_model_params, gen_vhdl_code\n",
    "\n",
    "# Wrap the layers so the HDL export functions can find them\n",
    "model.model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    model.layer1,\n",
    "    model.layer2,\n",
    "    model.layer3\n",
    ")\n",
    "\n",
    "number_of_layers, num_neurons, lut_sizes, number_of_inputs, number_of_classes = get_model_params(model)\n",
    "model_name = 'breast_lutnn'\n",
    "\n",
    "gen_vhdl_code(model, model_name, number_of_layers, number_of_classes, number_of_inputs, num_neurons, lut_sizes)\n",
    "print(f'VHDL code generated in data/VHDL/{model_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): LUTLayer(num_luts=1024, lut_size=4)\n",
      "  (2): LUTLayer(num_luts=512, lut_size=4)\n",
      "  (3): Aggregation(num_classes=2, tau=10.0)\n",
      ")\n",
      "tensor([[0, 0, 1,  ..., 0, 1, 1],\n",
      "        [0, 1, 0,  ..., 1, 0, 0],\n",
      "        [1, 0, 1,  ..., 1, 1, 0],\n",
      "        ...,\n",
      "        [1, 0, 1,  ..., 0, 1, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 1],\n",
      "        [1, 1, 0,  ..., 1, 0, 0]])\n",
      "tensor([[0, 0, 0,  ..., 0, 1, 1],\n",
      "        [1, 0, 0,  ..., 0, 1, 0],\n",
      "        [1, 1, 1,  ..., 1, 0, 1],\n",
      "        ...,\n",
      "        [1, 0, 1,  ..., 0, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 0, 1]])\n",
      "SystemVerilog code generated in data/sv/breast_lutnn/\n"
     ]
    }
   ],
   "source": [
    "# SV generation\n",
    "from hdl.convert2sv import gen_sv_code\n",
    "\n",
    "gen_sv_code(model, model_name, number_of_layers, number_of_classes, number_of_inputs, num_neurons, lut_sizes)\n",
    "print(f'SystemVerilog code generated in data/sv/{model_name}/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
